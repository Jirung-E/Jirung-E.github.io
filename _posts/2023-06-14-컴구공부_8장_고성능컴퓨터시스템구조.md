---
title: "컴구공부_8장_고성능컴퓨터시스템구조"
excerpt: "컴퓨터구조 기말고사 대비"
last_modified_at: 2023-06-14T23:34:00

categories:
  - Study

tags:
  - 병렬처리
  - GPU
  - CUDA

toc: true
toc_sticky: true
---

## 병렬처리
 - 작업단위 병렬성: 독립적인 작업 프로그램 단위로 병렬처리
 - 태스크단위 병렬성: 하나의 작업을 기능에 따라 분할하여 병렬처리
 - 스레드단위 병렬성: 동시에 처리될 수 있는 가장 작은 크기의 독립적인 단위 프로그램인 스레드 단위의 병렬처리
 - 명령어 단위 병렬성: 데이터의 의존성이 존재하지 않는 여러개의 명령어들을 동시에 수행하는 병렬처리

## 병렬컴퓨터의 분류
 - 명령어 스트림: 프로세서에 의해 실행되기 위하여 순서대로 나열된 명령어 코드들의 집합
 - 데이터 스트림: 그 명령어들을 실행하는데 필요한 순서대로 나열된 데이터들의 집합   

**명령어와 데이터의 스트림의 수에 따라 분류**
 - 단일 명령어 스트림 - 단일 데이터 스트림(SISD)
   + 단일 프로세서 시스템
   + 파이프라이닝, 슈퍼스칼라 구조를 이용해서 성능 개선
 - 단일 명령어 스트림 - 복수 데이터 스트림(SIMD)
   + 여러개의 프로세싱 유닛(PU)들로 구성
   + PU들의 동작은 모두 하나의 제어 유닛에 의해 통제
   + 모든 PU들은 하나의 명령어 스트림을 실행
   + 데이터 스트림은 여러개를 동시에 처리
 - 복수 명령어 스트림 - 단일 데이터 스트림(MISD)
   + 이런거 없다
 - 복수 명령어 스트림 - 복수 데이터 스트림(MIMD)
   + 여러개의 프로세서들이 서로 다른 명령어들과 데이터들을 처리
     - 밀결합 시스템
       + 공유기억장치 구조
       + 멀티코어 CPU, 다중프로세서 시스템
     - 소결합 시스템
       + 지역 기억장치를 가진 독립적인 컴퓨터 모듈로 구성
       + 프로세서간 통신은 메시지 전송 방식 이용
       + 분산처리시스템

### 기억장치 액세스 모델에 따른 분류

#### 균일 기억장치 액세스(Uniform Memory Access: UMA) 모델
 - 모든 프로세서들이 상호연결망에 의해 접속된 주기억장치를 공유한다
 - 프로세서들은 주기억장치의 어느 영역이든 액세스할수 있으며, 그에 걸리는 시간이 동일
 - ex) 멀티코어CPU가 한개 존재하는 컴퓨터
 - 하드웨어가 간단하고, 프로그래밍이 용이
 - 공유자원에 대한 경합이 높아지기 때문에 시스템 크기에 한계가 있다

#### 불균일 기억장치 액세스(Non-Uniform Memory Access: NUMA) 모델
 - 다수의 UMA모델들이 상호연결망에 의해 접속
 - 분산 공유기억장치 구조
 - 기억장치 액세스 시간은 기억장치의 위치에 따라 달라짐
   + 지역기억장치 액세스
   + 원격기억장치 액세스

### 시스템 구성 방법에 따른 분류

#### 대칭적 다중프로세서(Symmetric Multi-Processor: SMP)
 - 64개 이하의 프로세서들을 가지는 중대형급 시스템
 - 완전공유구조: 프로세서들이 시스템 내의 모든 자원들을 공유
 - 시스템 내에 하나의 OS만 존재
 - 대칭적
   + 모든 프로세서들이 필요 시 직접 OS코드 수행
   + 모든 프로세서들이 자원들을 동등한 권한으로 사용

##### 특징
 - 능력이 비슷한 프로세서들로 구성
 - 프로세서들이 기억장치와 I/O장치들을 공유, 상호연결망에 의해 접속
 - 모든 프로세서들은 동등한 권한을 가지며, 같은 수준의 기능들을 수행
 - 프로세서간 통신은 공유 기억장치를 이용
 - 작업 스케줄링이 하나의 OS에 의해 통합적으로 이루어짐
 - 공유 자원의 경합으로 인하여 시스템 크기에 한계

##### Master/Slave
 - SMP의 반대 개념
 - 능력이 다른 프로세서들로 구성 가능
 - Master는 모든 기억장치와 I/O장치에 접근 가능, Slave는 일부만 가능
 - Master가 Slave에게 할일을 넘겨주어 수행하게 함.

#### 대규모 병렬프로세서(Massively Parallel Processor)
 - 무공유구조를 기반으로 하는 대규모 병렬처리 시스템
 - 수백 혹은 수천개의 프로세싱 노드들로 구성
 - 간단한 구조의 노드 프로세서 사용
 - 마이크로-커널 수준의 노드OS 탑재
 - 노드들 간의 통신은 메시지 전송 방식 이용
 - 복잡도 높은 상호연결망 이용

#### 캐시-일관성 NUMA(Cache-Coherent NUMA: CC-NUMA)
 - 독립적인 노드들(UMA 혹은 NUMA 시스템)이 상호연결망에 의해 접속
 - 모든 노드들의 캐시 및 주기억장치들 사이에 데이터 일관성 유지
 - 시스템 내의 모든 기억장치들이 전역 주소공간을 가지는 공유기억장치 시스템으로 구성
 - 주요 장점: S/W 변경 없이 SMP보다 더 큰 시스템 구축 가능

#### 분산시스템
 - 독립적인 노드들이 전통적인 네트워크에 의해 접속
 - 노드들간의 정보 교환 혹은 병렬처리를 수행할 때만 네트워크를 이용하여 통신

#### 클러스터 컴퓨터
 - 모든 시스템 자원들을 단일 시스템 이미지로 통합
 - 저렴한 비용으로 병렬처리 시스템 구축 가능
 - 결함 대체 용이 -> 가용성 향상

## 다중프로세서 시스템 구조
 - MIMD조직, 여러개의 프로세서들이 비동기적으로 프로그램을 실행

### 공유기억장치 시스템
 - 밀결합구조, 주기억장치가 모든 프로세서들에 의해 공유
 - 상호연결구조

### 분산기억장치 시스템
 - 소결합구조
 - 각 프로세서가 자신의 지역 기억장치를 소유
 - 다른 프로세서들과의 통신은 메시지 전송

## 그래픽처리유닛(GPU)
### CUDA
 - 그리드: 하나의 병렬 커널에 의해 생성되는 스레드 전체
 - 블록: 그리드 내의 스레드들을 적절한 수의 스레드 들로 분할한 단위

#### 호스트-디바이스 간 정보 전송을 위한 함수들
 - cudaMalloc((void**)&Md, size);
 - cudaMemcpy(Md, M, size, cudaMemcpyHostToDevice);
 - cudaMemcpy(Md, M, size, cudaMemcpyDeviceToHost);
 - cudaFree(Md);

### GPU 기억장치 계층
 - 지역 기억장치: 각 스레드가 사용, 주로 레지스터 세트로 구현
 - 공유 기억장치: 같은 블록에 포함된 스레드들이 공동으로 사용
 - 전역 기억장치: 모든 응용프로그램들이 생성한 그리드들이 공유하는 기억장치, 호스트와 GPU간의 데이터 교환에도 사용됨
